{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f530e7f",
   "metadata": {},
   "source": [
    "# Natural Language Processing(NLP) for Text Classification Project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66090188",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d447e",
   "metadata": {},
   "source": [
    "welcome to the documentation/coding for NLP- based Text Classification project. This project focus on leveraging Natural Language Processing techniques to automatically categorize and classify text data into predefined categories or labels. Text classification plays a crucial role in various applications, including sentiments analysis, sparm detection, and content categorization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fe5271",
   "metadata": {},
   "source": [
    "# Project Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5815eb2",
   "metadata": {},
   "source": [
    "The primary goals of this project are as follows: \n",
    "    \n",
    "  1. Develop a robust text Classification model capable of accurately categorizing input text into predefined classes. \n",
    "  2. Explore and implement state-of-the-art NLP techniques to enhance the model's understanding of textual data.\n",
    "  3. Provide a scalable and efficient solution for automated text classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe8906",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529d9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6082a22",
   "metadata": {},
   "source": [
    "here, 'numpy', 'pandas', 'matplotlib', 'seaborn' are some libraries used for data analysis and visualization where as np, pd, plt, and sns aliases fpr brevity. this is a common conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1188b09",
   "metadata": {},
   "source": [
    "# Uploaded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169877cb",
   "metadata": {},
   "source": [
    "'pd.read_csv()' function is generally used for loading dataset into a pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51944ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"D:\\priya\\internship\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4153f6",
   "metadata": {},
   "source": [
    "now, we select first 10,000 rows of the Dataframe 'df' and assigns it to a new variable named 'data'. afterall, we can work with the subset of the data contained in the 'data' variable for further analysis or processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201e9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= df.iloc[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aac556",
   "metadata": {},
   "source": [
    "here, after slicing the Dataframe and assigning it to the variable 'data'. we used .head() method to display first few rows of the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a5f1d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b6fd3",
   "metadata": {},
   "source": [
    "we accessed the value in the 'review' column for the second row (index1) in the dataframe 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "959e52ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d881a",
   "metadata": {},
   "source": [
    "we used the '.value_counts()' method on the 'sentiment' column, showing the distribution of sentiments in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b561d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    5028\n",
       "negative    4972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c298a",
   "metadata": {},
   "source": [
    "'.isnull().sum()' is checking for the presence of null(missing) value in each column of the Dataframe 'data' and then, summing up the counts of these null values. if the count is 0 for all columns, it means there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608773ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56bb9e6",
   "metadata": {},
   "source": [
    "now, we will check all duplicates value in all rows of dataframe 'data'. if the counts is 0, it means there are no duplicate rows. if there are non 0, it indicates the number of rows are identical to other rows in Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c270572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed980c8",
   "metadata": {},
   "source": [
    "here, '.drop_duplicates' method are using on the dataframe 'data' to remove duplicated rows and modifying the dataframe in place setting 'inplace=True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8a9e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shwet\\AppData\\Local\\Temp\\ipykernel_4960\\2282015914.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd7521",
   "metadata": {},
   "source": [
    "now, we removed all duplicates rows and finally get 0 duplicated rows in dataframe 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52977f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b9a136",
   "metadata": {},
   "source": [
    "# Basic preprocessing\n",
    "Remove tags\n",
    "Lowercase\n",
    "Remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a9640",
   "metadata": {},
   "source": [
    "here, we define a function named 'remove_tags' that uses the 're' module (regular expresssions) to remove HTML tags from a given 'raw_text'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e106622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_tags(raw_text):\n",
    "    cleaned_text= re.sub(re.compile('<.*?>'),'', raw_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805eb539",
   "metadata": {},
   "source": [
    "now, we are attempting to apply the 'remove_tags' function to 'review' column of dataframe 'data'. however, there's a syntax issue in our substraction operation. if we want to create a new column with the cleaned text(without HTML tags)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8a61e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shwet\\AppData\\Local\\Temp\\ipykernel_4960\\3366883445.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['review']=data['review'].apply(remove_tags)\n"
     ]
    }
   ],
   "source": [
    "data['review']=data['review'].apply(remove_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c14ae",
   "metadata": {},
   "source": [
    "we are checking dataframe 'data' after preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b64192ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Fun, entertaining movie about WWII German spy ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Give me a break. How can anyone say that this ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>This movie is a bad movie. But after watching ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>This is a movie that was probably made to ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Smashing film about film-making. Shows the int...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9983 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     One of the other reviewers has mentioned that ...  positive\n",
       "1     A wonderful little production. The filming tec...  positive\n",
       "2     I thought this was a wonderful way to spend ti...  positive\n",
       "3     Basically there's a family where a little boy ...  negative\n",
       "4     Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                 ...       ...\n",
       "9995  Fun, entertaining movie about WWII German spy ...  positive\n",
       "9996  Give me a break. How can anyone say that this ...  negative\n",
       "9997  This movie is a bad movie. But after watching ...  negative\n",
       "9998  This is a movie that was probably made to ente...  negative\n",
       "9999  Smashing film about film-making. Shows the int...  positive\n",
       "\n",
       "[9983 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0ceb34",
   "metadata": {},
   "source": [
    "here, we are using the 'apply()' method along with lambda function to convert the text in the 'review' column of the dataframe 'data' to lowercase. this operation will transform all text in the 'review' column to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15480118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shwet\\AppData\\Local\\Temp\\ipykernel_4960\\2096597980.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['review']= data['review'].apply(lambda x:x.lower())\n"
     ]
    }
   ],
   "source": [
    "data['review']= data['review'].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3e3e9",
   "metadata": {},
   "source": [
    "now, we check dataframe 'data' for applied method is working or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83e943ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fun, entertaining movie about wwii german spy ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give me a break. how can anyone say that this ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>this movie is a bad movie. but after watching ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>this is a movie that was probably made to ente...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>smashing film about film-making. shows the int...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9983 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     one of the other reviewers has mentioned that ...  positive\n",
       "1     a wonderful little production. the filming tec...  positive\n",
       "2     i thought this was a wonderful way to spend ti...  positive\n",
       "3     basically there's a family where a little boy ...  negative\n",
       "4     petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                 ...       ...\n",
       "9995  fun, entertaining movie about wwii german spy ...  positive\n",
       "9996  give me a break. how can anyone say that this ...  negative\n",
       "9997  this movie is a bad movie. but after watching ...  negative\n",
       "9998  this is a movie that was probably made to ente...  negative\n",
       "9999  smashing film about film-making. shows the int...  positive\n",
       "\n",
       "[9983 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53428c10",
   "metadata": {},
   "source": [
    "there is a small typo in our import statement. nltk is stands for natural language toolkit. this code improt nltk library and then downloads the stopwords dataset, which is commonly used in Natural Language Processing(NLP) task for filtering out common words that usually don't carry much information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f32bbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d774e7b",
   "metadata": {},
   "source": [
    "we create a lambda function that splits each review into words, filters out the stop words, and joins the remaining words back into sentences. we apply this lambda function to the 'review' column of the Dataframe, modifying the content to exclude english stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c551428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shwet\\AppData\\Local\\Temp\\ipykernel_4960\\1737803637.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['review']=data['review'].apply(lambda x:[item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw_list=stopwords.words('english')\n",
    "data['review']=data['review'].apply(lambda x:[item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb9921",
   "metadata": {},
   "source": [
    "checking dataframe 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "637e28b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production. filming technique...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's family little boy (jake) thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fun, entertaining movie wwii german spy (julie...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give break. anyone say \"good hockey movie\"? kn...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>movie bad movie. watching endless series bad h...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>movie probably made entertain middle school, e...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>smashing film film-making. shows intense stran...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9983 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "0     one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1     wonderful little production. filming technique...  positive\n",
       "2     thought wonderful way spend time hot summer we...  positive\n",
       "3     basically there's family little boy (jake) thi...  negative\n",
       "4     petter mattei's \"love time money\" visually stu...  positive\n",
       "...                                                 ...       ...\n",
       "9995  fun, entertaining movie wwii german spy (julie...  positive\n",
       "9996  give break. anyone say \"good hockey movie\"? kn...  negative\n",
       "9997  movie bad movie. watching endless series bad h...  negative\n",
       "9998  movie probably made entertain middle school, e...  negative\n",
       "9999  smashing film film-making. shows intense stran...  positive\n",
       "\n",
       "[9983 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6feba25",
   "metadata": {},
   "source": [
    "here, we sperated the review and sentiment columns in x and y value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e60a4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data.iloc[:,0:1]\n",
    "y=data['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db37076f",
   "metadata": {},
   "source": [
    "display x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c611b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production. filming technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's family little boy (jake) thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love time money\" visually stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>fun, entertaining movie wwii german spy (julie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>give break. anyone say \"good hockey movie\"? kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>movie bad movie. watching endless series bad h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>movie probably made entertain middle school, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>smashing film film-making. shows intense stran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9983 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review\n",
       "0     one reviewers mentioned watching 1 oz episode ...\n",
       "1     wonderful little production. filming technique...\n",
       "2     thought wonderful way spend time hot summer we...\n",
       "3     basically there's family little boy (jake) thi...\n",
       "4     petter mattei's \"love time money\" visually stu...\n",
       "...                                                 ...\n",
       "9995  fun, entertaining movie wwii german spy (julie...\n",
       "9996  give break. anyone say \"good hockey movie\"? kn...\n",
       "9997  movie bad movie. watching endless series bad h...\n",
       "9998  movie probably made entertain middle school, e...\n",
       "9999  smashing film film-making. shows intense stran...\n",
       "\n",
       "[9983 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572a73a",
   "metadata": {},
   "source": [
    "display y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d45bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       positive\n",
       "1       positive\n",
       "2       positive\n",
       "3       negative\n",
       "4       positive\n",
       "          ...   \n",
       "9995    positive\n",
       "9996    negative\n",
       "9997    negative\n",
       "9998    negative\n",
       "9999    positive\n",
       "Name: sentiment, Length: 9983, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed81fd8",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1f399",
   "metadata": {},
   "source": [
    "here, this code is using for 'LabelEncoder' to transform categorial labels in variable 'y' into numerical values. the 'fit_transform' method fits the encoder to the unique labels in 'y' and transforms them into numerical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736cb75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y= encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55195d31",
   "metadata": {},
   "source": [
    "now. after displaying y.. we can see that every positive and negative are displaying as 0 or 1 in numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84bbbc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db262650",
   "metadata": {},
   "source": [
    "the code uses the 'train_test_split' function from scikit-learn and testing sets. the 'test_size' parameter specifices the proportion of the dataset to include in the test split, and 'random_state' ensures reproducibility by fixing the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "775c7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2363e466",
   "metadata": {},
   "source": [
    "for knowing the shape of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "508953c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a6029e",
   "metadata": {},
   "source": [
    "X_test information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71a2eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1997 entries, 5333 to 2573\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   review  1997 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 31.2+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952221f",
   "metadata": {},
   "source": [
    "applying BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca0e21",
   "metadata": {},
   "source": [
    "here, we are using scikit-learn where CountVectorizer() function is useful to convert text data into bag-of-words representation. \n",
    "this code intializes a 'CountVectorizer' fits it to the training data (X_train['review']) tranform both the training and testing data into bag-of-words representations, and then checks the shape of training data as X_train_bow.shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27b82b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b107960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv= CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af329be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94ecdf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7986, 48282)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82da9b85",
   "metadata": {},
   "source": [
    "now, we are using scikit-learn's Gaussian Naive Bayes Classifier('GaussianNB') and fitting it to training data. \n",
    "This code initializes a Gaussian Naive Bayes classifier, 'gnb', and fits it to the bag-of-words representations of the training data('X_train_bow') with corresponding labels ('y_train')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4229ad7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb= GaussianNB()\n",
    "gnb.fit(X_train_bow,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4be0d7",
   "metadata": {},
   "source": [
    "this code will calculates predictions ('y_pred') using the trained Gaussian Naive bayes model on the test data('X_test_bow') and then computes the accuracy using 'accuracy_score' from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d1f48f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324486730095142"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=gnb.predict(X_test_bow)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22592309",
   "metadata": {},
   "source": [
    "for printing the confusion matrix, which is a table showing the number of true positive, true negative, false positive, and false negative predictions, it's a useful tool for evaluating the performance of classiication model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "452689dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[717, 235],\n",
       "       [499, 546]], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f0fa9",
   "metadata": {},
   "source": [
    "1. added the correct syntax to create a 'RandomForestClassifier' instance ('rf=RandomForestClassifier()').\n",
    "2. corrected the variable name from 'f.predict' to 'rf.predict'.\n",
    "3. calculating accuracy using 'accuracy_score' and stored it in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0152304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c09c2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8517776664997496"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred=rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcd071",
   "metadata": {},
   "source": [
    "we are trying to limit the number of features with 'CountVectorizer' and then we use a RandomForestClassifier.\n",
    "1. set 'max_features' parameter correctly in 'CountVectorizer' .\n",
    "2. Corrected variable names, replacing '-' with '=' for assignments.\n",
    "3. used the correct syntax for 'y_pred' and 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "110090af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8377566349524287"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_features=3000)\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "\n",
    "rf=rf=RandomForestClassifier()\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred=rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c47a0d5",
   "metadata": {},
   "source": [
    "this code uses a 'CountVectorizer' with n-grams and a limit on the number of features, and it trains a RandomForestClassifier on the resulting bag-of-words representation of the training data. the accuracy of the model is then evaluated on the test data.\n",
    "1. corrected the assinment operator from '-' to '=' for 'max_features'.\n",
    "2. specified the 'ngram_range' parameter as '(1,3)' to include unigrams, bigrams, and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4378fdd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8437656484727091"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(ngram_range=(1,3),max_features=5000)\n",
    "X_train_bow = cv.fit_transform(X_train['review']).toarray()\n",
    "X_test_bow = cv.transform(X_test['review']).toarray()\n",
    "\n",
    "rf=rf=RandomForestClassifier()\n",
    "rf.fit(X_train_bow, y_train)\n",
    "y_pred=rf.predict(X_test_bow)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0a946",
   "metadata": {},
   "source": [
    "# Using Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4778c8",
   "metadata": {},
   "source": [
    "this code inialixes a 'TfidfVectorizer' fits it to training data, and transforms both the training and test data into TF-IDF representation.\n",
    "1. corrected the variable assignment from 'tfidf' to 'x_train_tfidf'.\n",
    "2. used the 'fit_transform' method to transform the training data and the 'transform' method to transform the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9592a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf= TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train['review']).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test['review']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce56ab",
   "metadata": {},
   "source": [
    "this code initialixes a RandomForestClassifier, fits it to training data with TF-IDF features ('X_train_tfidf'), predicts labels on the test data with TF-ITD features ('X_test_tfidf'), and calculates the accuracy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "757abfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522784176264396"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred=rf.predict(X_test_tfidf)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcb4c64",
   "metadata": {},
   "source": [
    "# Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc4d89f",
   "metadata": {},
   "source": [
    "here, \n",
    "1. we import gensim library which is popular python library for topic modeling and document similarity analysis. \n",
    "2. after fixing this, we can proceed with the rest code of our code for sentence tokenization using NLTK and simple preprocessing using Gensim.\n",
    "3. we are importing the 'sent_tokenize' function from nltk for sentence tokenization and 'simple_preprocess' function from gensim for text preprocessing. \n",
    "\n",
    "these functions can be useful for preparing text data for tasks such as natural language processing, topic modelling, or document similarity analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8dfa369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44509302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shwet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c9c5ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8877b51",
   "metadata": {},
   "source": [
    "now, we used nested loop to process text data:\n",
    "     1. for doc in data['review']:this outer loop iterates over each document in the 'review' column of the 'data' variable. it assumes 'data' is a DatatFrame or a similar structure.\n",
    "     2. raw_sent= sent_tokenize(doc): inside the outer loop, the code uses 'sent_tokenize' from nltk to tokenize the sentences in the current document ('doc')and stores  them in the 'raw_sent' variable.\n",
    "     3. for sent in raw_sent: the inner loop iterates over each sentence obtained from 'sent_tokenize' within the current document.\n",
    "     4. story.append(simple_preprocess(sent)): for each sentences, the code uses 'simple_preprocessing' from gensim to perform basic text preprocessing, such as lowercasing and tokenization. the preprocessed sentence is then append to the 'story' list.\n",
    "\n",
    "in summary, this code processes a collection of documents, tokenizes each document into sentences, and then further tokenizes and preprocesses each sentence using gensim. The preprocessed sentences are stored in 'story=[]' list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aeac4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "story=[]\n",
    "for doc in data['review']:\n",
    "    raw_sent= sent_tokenize(doc)\n",
    "    for sent in raw_sent:\n",
    "        story.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060badf0",
   "metadata": {},
   "source": [
    "we are training a word2vec model using gensim on the 'story' data. let me explain the components of your code:\n",
    "    \n",
    "     1. model=gensim.models.Word2Vec(window=10,min_count=2): this initializes a word2vec model with a context window size of 10('window=10') and a minimum word frequency of 2('min_count=2'). the context window defines the maximum distance betwen the current and predicted word within a sentence during training.\n",
    "     2. model.train(story, total_examples=model.corpus_count, epochs=model.epochs): this lines trains the word2vec model on the 'story' data. it uses the sentences in 'story as training examples. 'total_examples' is set to 'model.corpus_count' (the toatal number of sentences), and 'epochs' is set to 'model.epochs'(the number of iterations over the data).\n",
    "     3. len(model.wv.index_to_key): this calculates the number of unique words in the trained word2vec model by retrieving the index-to-key mapping. the length of this mapping corresponds to vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "327d433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7e7ec865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92354293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5876315, 6212140)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(story, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "642b2e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31845"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82b954",
   "metadata": {},
   "source": [
    "here, \n",
    "1. we define a fuction document_vector(doc): that takes a single argument doc. this function is designed to calculate the mean vector of word embeddings for a given document.\n",
    "2. then, we create a list comprehension that iterates through each word in the input document('doc'). it filters out words that are not present in word2vec model's vacubalory words from the document.\n",
    "3. finally, lines calculates the mean vector of word embeddings for the remaining words in the document. it uses numpy's 'np.mean' function with axis=0 to compute the mean along the rows, resulting in single mean vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0410ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    #remove out of vocab words\n",
    "    doc= [word for word in doc.split() if word in model.wv.index_to_key]\n",
    "    return np.mean(model.wv[doc],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7d83a",
   "metadata": {},
   "source": [
    "we are trying to calculate the mean vector of word embeddings for the first document in the 'review' column of our dataframe'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "688551e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20446354,  0.48086828,  0.04406572,  0.17868163, -0.11360488,\n",
       "       -0.6648532 ,  0.33844563,  1.0647515 , -0.17490748, -0.3658816 ,\n",
       "       -0.2453849 , -0.5312085 , -0.01779767,  0.22050327, -0.05921424,\n",
       "       -0.13726705,  0.07167196, -0.2636031 ,  0.0520041 , -0.67296475,\n",
       "        0.12792939,  0.28691745,  0.32737443, -0.2829517 , -0.3757647 ,\n",
       "       -0.07819744, -0.3553448 , -0.03684964, -0.484629  ,  0.20674957,\n",
       "        0.5017143 , -0.07333556,  0.3365158 , -0.3449094 , -0.23993956,\n",
       "        0.48830262,  0.10382417, -0.55608785, -0.32816786, -0.907156  ,\n",
       "        0.08772528, -0.3460025 , -0.00423646, -0.11687607,  0.42869237,\n",
       "       -0.20204553, -0.31456494, -0.27588758,  0.2633517 ,  0.38322195,\n",
       "        0.21068761, -0.43524468, -0.3621421 , -0.13118613, -0.22107878,\n",
       "        0.08333623,  0.16229126, -0.17648011, -0.44074973,  0.09028256,\n",
       "        0.12995642, -0.06009729,  0.1622938 , -0.1013926 , -0.5386657 ,\n",
       "        0.45121804, -0.01630789,  0.20510393, -0.5400061 ,  0.3602311 ,\n",
       "       -0.17233877,  0.14667949,  0.5284006 , -0.05447913,  0.4917997 ,\n",
       "        0.18960524, -0.07868512, -0.12518214, -0.5774978 ,  0.09780986,\n",
       "       -0.28420094,  0.04555489, -0.5001161 ,  0.47424603, -0.3291537 ,\n",
       "       -0.11096247,  0.0184214 ,  0.18067966,  0.20875515,  0.10171606,\n",
       "        0.43380746,  0.2608811 , -0.04808278,  0.13327613,  0.51606494,\n",
       "        0.17997886,  0.10915627, -0.20405272, -0.04510144, -0.170658  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vector(df['review'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ed3d8",
   "metadata": {},
   "source": [
    "'tqdm' library is used to create progress bars in python, making it easier to visualize the progress of an iteration or a task. the name 'tqdm' stands for 'taqaddum' in arabic, which means 'progress.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "713492fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76affbd1",
   "metadata": {},
   "source": [
    "we are using 'tqdm' to track the progress of processing documents and appending their corresponding vectors to a list 'X' using the 'document_vector'function. using 'document_vector' function. this is a good practice when dealing with large datasets or time-consuming operations.\n",
    "1. for doc in tqdm(data['review'].values): this loop iterates over each document in the 'review' column of our dataset'data'. the tqdm is used to create a progress bar to visualize the iteration progress.\n",
    "2.  X.append(document_vector(doc)): for each document, the 'document_vector' fuction is called is calculate the mean vector of word embeddings. the resulting vector is then appended to the list 'x'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ef5695c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9983/9983 [11:00<00:00, 15.11it/s]\n"
     ]
    }
   ],
   "source": [
    "X= []\n",
    "for doc in tqdm(data['review'].values):\n",
    "    X.append(document_vector(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30590461",
   "metadata": {},
   "source": [
    "here, first line converts the list x into a numpy array using np.array(x) method.\n",
    "and other prints the shape of the resulting numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b8c6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fcd3b531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9983, 100)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed6cca",
   "metadata": {},
   "source": [
    "now, we imported the labelencoder for changing the sentiments which is in positive and negative values into numerical like 0,1.\n",
    "then all sentiments are assign in y after changing sentiments in 0,1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "729ed9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "y= encoder.fit_transform(data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dcb475",
   "metadata": {},
   "source": [
    "display y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "db91b559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7720e",
   "metadata": {},
   "source": [
    "after changing the value of X and y in numerically, then we use all data for train and test the data. which is used in train_test_split from scikit-library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fed7d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e081c",
   "metadata": {},
   "source": [
    "here imported GaussianNB, accuracy_score from naive_bayes,metrics scikit learn libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "11a51692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994beffc",
   "metadata": {},
   "source": [
    "finally, model is ready and we can predict the X_test which assign in y_pred and atlast calculate the accuracy score by using matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "21c30f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155733600400601"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb=GaussianNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "y_pred=mnb.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68085882",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6ae79",
   "metadata": {},
   "source": [
    "In this NLP classification Project, we achieved a commendable accuracy score approximately 71.56%. the model demonstrated the capability to effectively classify text the data into predefined categories. however, it's essential to intrepret this accuracy score in the context of specific objective and requirements of the project. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
